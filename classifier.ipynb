{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-20T01:00:37.949806Z","iopub.execute_input":"2023-09-20T01:00:37.950233Z","iopub.status.idle":"2023-09-20T01:00:37.988013Z","shell.execute_reply.started":"2023-09-20T01:00:37.950188Z","shell.execute_reply":"2023-09-20T01:00:37.986714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nimp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=10, verbose=2, imputation_order='roman',random_state=0)\n#X=imp.fit_transform(X)\ndef isnumber(x):\n    try:\n        float(x)\n        return True\n    except:\n        return False\n\n#Each training data set has NaN values removed (could also split by label and impute this)\nLF_train_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/LF_train.csv',  sep=',',  header=0)\nLH_train_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/LH_train.csv',  sep=',',  header=0)\nRF_train_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/RF_train.csv',  sep=',',  header=0)\nRH_train_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/RH_train.csv',  sep=',',  header=0)\nLF_train_pred=LF_train_df[LF_train_df.columns[6]].to_numpy()\nLH_train_pred=LH_train_df[LH_train_df.columns[6]].to_numpy()\nRF_train_pred=RF_train_df[RF_train_df.columns[6]].to_numpy()\nRH_train_pred=RH_train_df[RH_train_df.columns[6]].to_numpy()\nLF_train_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\nLH_train_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\nRF_train_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\nRH_train_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\n\n#Test points\nLF_test_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/LF_test.csv',  sep=',',  header=0)\nLF_ids = LF_test_df['id']\nLH_test_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/LH_test.csv',  sep=',',  header=0)\nLH_ids = LH_test_df['id']\nRF_test_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/RF_test.csv',  sep=',',  header=0)\nRF_ids = RF_test_df['id']\nRH_test_df = pd.read_csv('../input/cs4780-spring-2023-kaggle-competition/RH_test.csv',  sep=',',  header=0)\nRH_ids = RH_test_df['id']\n\n\nfor col in LF_train_df.columns:\n    if(col!=('LF'or 'LH' or 'RH' or 'RF')):\n        LF_train_df[col]=pd.to_numeric(LF_train_df[col], errors='coerce')\n        LH_train_df[col]=pd.to_numeric(LH_train_df[col], errors='coerce')\n        RF_train_df[col]=pd.to_numeric(RF_train_df[col], errors='coerce')\n        RH_train_df[col]=pd.to_numeric(RH_train_df[col], errors='coerce')\n        LF_train_df[col] = LF_train_df[col].fillna(LF_train_df.groupby('LF')[col].transform('mean'))\n        LH_train_df[col] = LH_train_df[col].fillna(LH_train_df.groupby('LH')[col].transform('mean'))\n        RF_train_df[col] = RF_train_df[col].fillna(RF_train_df.groupby('RF')[col].transform('mean'))\n        RH_train_df[col] =RH_train_df[col].fillna(RH_train_df.groupby('RH')[col].transform('mean'))\n        LF_test_df[col] = pd.to_numeric(LF_test_df[col], errors='coerce')\n        LH_test_df[col] = pd.to_numeric(LH_test_df[col], errors='coerce')\n        RF_test_df[col] = pd.to_numeric(RF_test_df[col], errors='coerce')\n        RH_test_df[col] = pd.to_numeric(RH_test_df[col], errors='coerce')\n\nLF_train_df.drop(columns=['LF'], inplace=True)\nLH_train_df.drop(columns=['LH'], inplace=True)\nRF_train_df.drop(columns=['RF'], inplace=True)\nRH_train_df.drop(columns=['RH'], inplace=True)\n\n\n#Each test data set has missing values replaced with the mean of the column\nLF_test_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\nLF_test_df.fillna(LF_test_df.median(), inplace=True)\n\nLH_test_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\nLH_test_df.fillna(LH_test_df.median(), inplace=True)\n\nRF_test_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\nRF_test_df.fillna(RF_test_df.median(), inplace=True)\n\nRH_test_df.drop(columns=['gait','Gait','dob','id','forceplate_date'], inplace=True)\nRH_test_df.fillna(RH_test_df.median(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T22:26:20.585922Z","iopub.execute_input":"2023-08-14T22:26:20.586754Z","iopub.status.idle":"2023-08-14T22:26:24.791885Z","shell.execute_reply.started":"2023-08-14T22:26:20.586704Z","shell.execute_reply":"2023-08-14T22:26:24.790283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score\n\nsc = StandardScaler()\nsc.fit(LF_train_df)\nLF_train_std = sc.transform(LF_train_df)\nLF_test_std = sc.transform(LF_test_df)\n\n# Training a SVM classifier using SVC class\nsvm = SVC(kernel= 'linear', random_state=2, C=0.0076)\nsvm.fit(LF_train_std, LF_train_pred)\nLF_pred = svm.predict(LF_test_std)\n\nsc = StandardScaler()\nsc.fit(LH_train_df)\nLH_train_std = sc.transform(LH_train_df)\nLH_test_std = sc.transform(LH_test_df)\n# Training a SVM classifier using SVC class\nsvm = SVC(kernel= 'linear', random_state=2, C=0.0076)\nsvm.fit(LH_train_std, LH_train_pred)\nLH_pred = svm.predict(LH_test_std)\n\nsc = StandardScaler()\nsc.fit(RF_train_df)\nRF_train_std = sc.transform(RF_train_df)\nRF_test_std = sc.transform(RF_test_df)\n# Training a SVM classifier using SVC class\nsvm = SVC(kernel= 'linear', random_state=2, C=0.0076)\nsvm.fit(RF_train_std, RF_train_pred)\nRF_pred = svm.predict(RF_test_std)\n\nsc = StandardScaler()\nsc.fit(RH_train_df)\nRH_train_std = sc.transform(RH_train_df)\nRH_test_std = sc.transform(RH_test_df)\n# Training a SVM classifier using SVC class\nsvm = SVC(kernel= 'linear', random_state=2, C=0.0076)\nsvm.fit(RH_train_std, RH_train_pred)\nRH_pred = svm.predict(RH_test_std)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T22:26:24.793328Z","iopub.execute_input":"2023-08-14T22:26:24.793991Z","iopub.status.idle":"2023-08-14T22:26:24.885811Z","shell.execute_reply.started":"2023-08-14T22:26:24.793951Z","shell.execute_reply":"2023-08-14T22:26:24.884817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv \nLF_data = []\n\nids = LF_ids\nfor i in range(len(LF_test_df)):\n    pt = [ids[i],LF_pred[i]]\n    LF_data += [pt]\n\nfilename = \"LF_test_labels.csv\"\nfields =['id','LF']\nwith open(filename, 'w') as csvfile: \n    csvwriter = csv.writer(csvfile) \n        \n    csvwriter.writerow(fields) \n        \n    csvwriter.writerows(LF_data)    \n###\n\nLH_data = []\n\nids = LH_ids\nfor i in range(len(LH_test_df)):\n    pt = [ids[i],LH_pred[i]]\n    LH_data += [pt]\n\nfilename = \"LH_test_labels.csv\"\nfields =['id','LH']\nwith open(filename, 'w') as csvfile: \n    csvwriter = csv.writer(csvfile) \n        \n    csvwriter.writerow(fields) \n        \n    csvwriter.writerows(LH_data)    \n###\n\nRF_data = []\n\nids = RF_ids\nfor i in range(len(RF_test_df)):\n    pt = [ids[i],RF_pred[i]]\n    RF_data += [pt]\n\nfilename = \"RF_test_labels.csv\"\nfields =['id','RF']\nwith open(filename, 'w') as csvfile: \n    csvwriter = csv.writer(csvfile) \n        \n    csvwriter.writerow(fields) \n        \n    csvwriter.writerows(RF_data)  \n\n###\nRH_data = []\nids = RH_ids\nfor i in range(len(RH_test_df)):\n    pt = [ids[i],RH_pred[i]]\n    RH_data += [pt]\n\nfilename = \"RH_test_labels.csv\"\nfields =['id','RH']\nwith open(filename, 'w') as csvfile: \n    csvwriter = csv.writer(csvfile) \n        \n    csvwriter.writerow(fields) \n        \n    csvwriter.writerows(RH_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T22:26:24.887806Z","iopub.execute_input":"2023-08-14T22:26:24.889138Z","iopub.status.idle":"2023-08-14T22:26:24.906328Z","shell.execute_reply.started":"2023-08-14T22:26:24.889096Z","shell.execute_reply":"2023-08-14T22:26:24.904880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n\"\"\"\nThis is a file that will help you convert your individual predictions to the final prediction. \nIn the same directory as this file, you should have the following 4 files:\n  - LF_test_labels.csv - with at least two columns, 'id' and 'LF'\n  - LH_test_labels.csv - with at least two columns, 'id' and 'LH'\n  - RF_test_labels.csv - with at least two columns, 'id' and 'RF'\n  - RH_test_labels.csv - with at least two columns, 'id' and 'RH'\n\nRunning this script will convert these four files into a single CSV file, submission.csv, by\nmutating the IDs so that they also include the leg that is being checked.\n\"\"\"\n\nlegs = [\"LF\", \"LH\", \"RF\", \"RH\"]\n\ndfs = []\n\nfor leg in legs:\n    # read in the file\n    test_prediction = pd.read_csv(f\"{leg}_test_labels.csv\")\n    # append the abbreviation for the leg\n    test_prediction['id'] = test_prediction['id'].astype(str) + f\"_{leg}\"\n    # rename the label column\n    test_prediction['label'] = test_prediction[leg]\n    # exclude any potential additional columns\n    dfs.append(test_prediction[['id', 'label']])\n\nfinal_df = pd.concat(dfs)\nfinal_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T22:26:24.908013Z","iopub.execute_input":"2023-08-14T22:26:24.908500Z","iopub.status.idle":"2023-08-14T22:26:24.945672Z","shell.execute_reply.started":"2023-08-14T22:26:24.908452Z","shell.execute_reply":"2023-08-14T22:26:24.944188Z"},"trusted":true},"execution_count":null,"outputs":[]}]}